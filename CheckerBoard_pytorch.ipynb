{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvqsmCNXQgBZKgz3mwEZRf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yango4you/Colab/blob/master/CheckerBoard_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from compressai.ops import ste_round\n",
        "from compressai.models import JointAutoregressiveHierarchicalPriors, Cheng2020Anchor\n",
        "from compressai.ans import BufferedRansEncoder, RansDecoder"
      ],
      "metadata": {
        "id": "fsJ_gNwBjlOg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CheckerboardContext(nn.Conv2d):\n",
        "    \"\"\"\n",
        "    if kernel_size == (5, 5)\n",
        "    then mask:\n",
        "        [[0., 1., 0., 1., 0.],\n",
        "        [1., 0., 1., 0., 1.],\n",
        "        [0., 1., 0., 1., 0.],\n",
        "        [1., 0., 1., 0., 1.],\n",
        "        [0., 1., 0., 1., 0.]]\n",
        "    0: non-anchor\n",
        "    1: anchor\n",
        "    \"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.register_buffer(\"mask\", torch.zeros_like(self.weight.data))\n",
        "\n",
        "        self.mask[:, :, 0::2, 1::2] = 1\n",
        "        self.mask[:, :, 1::2, 0::2] = 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.weight.data *= self.mask\n",
        "        out = super().forward(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\"\"\"\n",
        "if __name__ == '__main__':\n",
        "    ckbd = CheckerboardContext(in_channels=3, out_channels=3, kernel_size=5, stride=1, padding=2, bias=False)\n",
        "    # print(ckbd.mask)\n",
        "    anchor = torch.zeros([1, 3, 8, 8])\n",
        "    anchor[:, :, 0::2, 1::2] = 1\n",
        "    anchor[:, :, 1::2, 0::2] = 1\n",
        "    # print(anchor)\n",
        "    print(ckbd(anchor))\n",
        "\n",
        "\n",
        "ckbd(anchor):\n",
        "\n",
        "          [-3.9174e-01,  0.0000e+00, -5.6143e-01,  0.0000e+00, -5.6143e-01,\n",
        "            0.0000e+00, -4.6364e-01,  0.0000e+00],\n",
        "          [ 0.0000e+00, -2.6317e-01,  0.0000e+00, -3.3227e-01,  0.0000e+00,\n",
        "           -3.3227e-01,  0.0000e+00, -1.2223e-03],\n",
        "          [-3.3980e-01,  0.0000e+00, -3.0401e-01,  0.0000e+00, -3.0401e-01,\n",
        "            0.0000e+00, -1.9141e-01,  0.0000e+00],\n",
        "          [ 0.0000e+00, -2.3491e-01,  0.0000e+00, -3.0401e-01,  0.0000e+00,\n",
        "           -3.0401e-01,  0.0000e+00,  1.3273e-01],\n",
        "          [-3.3980e-01,  0.0000e+00, -3.0401e-01,  0.0000e+00, -3.0401e-01,\n",
        "            0.0000e+00, -1.9141e-01,  0.0000e+00],\n",
        "          [ 0.0000e+00, -2.3491e-01,  0.0000e+00, -3.0401e-01,  0.0000e+00,\n",
        "           -3.0401e-01,  0.0000e+00,  1.3273e-01],\n",
        "          [-2.6121e-01,  0.0000e+00, -1.8591e-01,  0.0000e+00, -1.8591e-01,\n",
        "            0.0000e+00, -7.3309e-02,  0.0000e+00],\n",
        "          [ 0.0000e+00,  5.6478e-02,  0.0000e+00,  1.2801e-01,  0.0000e+00,\n",
        "            1.2801e-01,  0.0000e+00,  3.8838e-01]],\n",
        "\n",
        "when training and testing, bias = True\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "c-c9HL-st4HI",
        "outputId": "24a61c13-7fb4-43d8-b413-d620baddb20d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nif __name__ == '__main__':\\n    ckbd = CheckerboardContext(in_channels=3, out_channels=3, kernel_size=5, stride=1, padding=2, bias=False)\\n    # print(ckbd.mask)\\n    anchor = torch.zeros([1, 3, 8, 8])\\n    anchor[:, :, 0::2, 1::2] = 1\\n    anchor[:, :, 1::2, 0::2] = 1\\n    # print(anchor)\\n    print(ckbd(anchor))\\n\\n\\nckbd(anchor):\\n\\n          [-3.9174e-01,  0.0000e+00, -5.6143e-01,  0.0000e+00, -5.6143e-01,\\n            0.0000e+00, -4.6364e-01,  0.0000e+00],\\n          [ 0.0000e+00, -2.6317e-01,  0.0000e+00, -3.3227e-01,  0.0000e+00,\\n           -3.3227e-01,  0.0000e+00, -1.2223e-03],\\n          [-3.3980e-01,  0.0000e+00, -3.0401e-01,  0.0000e+00, -3.0401e-01,\\n            0.0000e+00, -1.9141e-01,  0.0000e+00],\\n          [ 0.0000e+00, -2.3491e-01,  0.0000e+00, -3.0401e-01,  0.0000e+00,\\n           -3.0401e-01,  0.0000e+00,  1.3273e-01],\\n          [-3.3980e-01,  0.0000e+00, -3.0401e-01,  0.0000e+00, -3.0401e-01,\\n            0.0000e+00, -1.9141e-01,  0.0000e+00],\\n          [ 0.0000e+00, -2.3491e-01,  0.0000e+00, -3.0401e-01,  0.0000e+00,\\n           -3.0401e-01,  0.0000e+00,  1.3273e-01],\\n          [-2.6121e-01,  0.0000e+00, -1.8591e-01,  0.0000e+00, -1.8591e-01,\\n            0.0000e+00, -7.3309e-02,  0.0000e+00],\\n          [ 0.0000e+00,  5.6478e-02,  0.0000e+00,  1.2801e-01,  0.0000e+00,\\n            1.2801e-01,  0.0000e+00,  3.8838e-01]],\\n\\nwhen training and testing, bias = True\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Cheng2020AnchorwithCheckerboard(Cheng2020Anchor):\n",
        "    \"\"\"\n",
        "    Shared entropy_parameters model for anchor and non-anchor.\n",
        "    Using two entropy parameter modules for anchor and non-anchor part may improve the performace.\n",
        "    \"\"\"\n",
        "    def __init__(self, N=192, **kwargs):\n",
        "        super().__init__(N, **kwargs)\n",
        "        self.context_prediction = CheckerboardContext(\n",
        "            in_channels = N, out_channels = N * 2, kernel_size=5, stride=1, padding=2\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Training by adding uniform noise.\n",
        "        Due to 1x1 receptive field of entropy parameters module and aun,\n",
        "        we can mask the anchor part of ctx_params for one-pass coding.\n",
        "        \"\"\"\n",
        "        y = self.g_a(x)\n",
        "        z = self.h_a(y)\n",
        "        z_hat, z_likelihoods = self.entropy_bottleneck(z)\n",
        "        y_hat = self.gaussian_conditional.quantize(\n",
        "            y, \"noise\" if self.training else \"dequantize\"\n",
        "        )\n",
        "        hyper_params = self.h_s(z_hat)\n",
        "        ctx_params = self.context_prediction(y_hat)\n",
        "        # mask anchor\n",
        "        ctx_params[:, :, 0::2, 1::2] = 0\n",
        "        ctx_params[:, :, 1::2, 0::2] = 0\n",
        "        gaussian_params = self.entropy_parameters(torch.cat([ctx_params, hyper_params], dim=1))\n",
        "        scales_hat, means_hat = gaussian_params.chunk(2, 1)\n",
        "        _, y_likelihoods = self.gaussian_conditional(y, scales_hat, means=means_hat)\n",
        "        x_hat = self.g_s(y_hat)\n",
        "        return {\n",
        "            \"x_hat\": x_hat,\n",
        "            \"likelihoods\": {\"y\": y_likelihoods, \"z\": z_likelihoods},\n",
        "        }\n",
        "\n",
        "    def validate(self, x):\n",
        "        \"\"\"\n",
        "        Estimate true distortion by ste(y-means) + means instead of adding uniform noise.\n",
        "        This function can also be used to train a LIC model.\n",
        "        \"\"\"\n",
        "        y = self.g_a(x)\n",
        "        z = self.h_a(y)\n",
        "        _, z_likelihoods = self.entropy_bottleneck(z)\n",
        "        z_offset = self.entropy_bottleneck._get_medians()\n",
        "        z_hat = ste_round(z - z_offset) + z_offset\n",
        "        hyper_params = self.h_s(z_hat)\n",
        "        ctx_params_anchor = torch.zeros([y.size(0), y.size(1) * 2, y.size(2), y.size(3)], device=y.device)\n",
        "        gaussian_params_anchor = self.entropy_parameters(torch.cat([ctx_params_anchor, hyper_params], dim=1))\n",
        "        # mask non-anchor\n",
        "        gaussian_params_anchor[:, :, 0::2, 0::2] = 0\n",
        "        gaussian_params_anchor[:, :, 1::2, 1::2] = 0\n",
        "        scales_anchor, means_anchor = gaussian_params_anchor.chunk(2, 1)\n",
        "        ctx_params = self.context_prediction(ste_round(y - means_anchor) + means_anchor)\n",
        "        # mask anchor\n",
        "        ctx_params[:, :, 0::2, 1::2] = 0\n",
        "        ctx_params[:, :, 1::2, 0::2] = 0\n",
        "        gaussian_params = self.entropy_parameters(torch.cat([ctx_params, hyper_params], dim=1))\n",
        "        scales_hat, means_hat = gaussian_params.chunk(2, 1)\n",
        "        y_hat = ste_round(y - means_hat) + means_hat\n",
        "        _, y_likelihoods = self.gaussian_conditional(y, scales_hat, means=means_hat)\n",
        "        x_hat = self.g_s(y_hat)\n",
        "        return {\n",
        "            \"x_hat\": x_hat,\n",
        "            \"likelihoods\": {\"y\": y_likelihoods, \"z\": z_likelihoods},\n",
        "        }\n",
        "\n",
        "    def compress(self, x):\n",
        "        \"\"\"\n",
        "        Compress by ste(y-mu) + mu, which leads to two-pass encoding.\n",
        "        For one-pass encoding, you can use Round(y) and range-coder for AE/AD.\n",
        "        When adopting range-coder, this repo https://github.com/ZhengxueCheng/Learned-Image-Compression-with-GMM-and-Attention may be helpful.\n",
        "        \"\"\"\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        cdf = self.gaussian_conditional.quantized_cdf.tolist()\n",
        "        cdf_lengths = self.gaussian_conditional.cdf_length.reshape(-1).int().tolist()\n",
        "        offsets = self.gaussian_conditional.offset.reshape(-1).int().tolist()\n",
        "        encoder = BufferedRansEncoder()\n",
        "        symbols_list = []\n",
        "        indexes_list = []\n",
        "        y_strings = []\n",
        "\n",
        "        y = self.g_a(x)\n",
        "        z = self.h_a(y)\n",
        "        z_strings = self.entropy_bottleneck.compress(z)\n",
        "        z_hat = self.entropy_bottleneck.decompress(z_strings, z.size()[-2:])\n",
        "\n",
        "        hyper_params = self.h_s(z_hat)\n",
        "        ctx_params_anchor = torch.zeros([y.size(0), y.size(1) * 2, y.size(2), y.size(3)], device=y.device)\n",
        "        gaussian_params_anchor = self.entropy_parameters(torch.cat([ctx_params_anchor, hyper_params], dim=1))\n",
        "        scales_anchor, means_anchor = gaussian_params_anchor.chunk(2, 1)\n",
        "        anchor_hat = self.compress_anchor(y, scales_anchor, means_anchor, symbols_list, indexes_list)\n",
        "\n",
        "        ctx_params = self.context_prediction(anchor_hat)\n",
        "        gaussian_params = self.entropy_parameters(torch.cat([ctx_params, hyper_params], dim=1))\n",
        "        scales_nonanchor, means_nonanchor = gaussian_params.chunk(2, 1)\n",
        "        nonanchor_hat = self.compress_nonanchor(y, scales_nonanchor, means_nonanchor, symbols_list, indexes_list)\n",
        "\n",
        "        encoder.encode_with_indexes(symbols_list, indexes_list, cdf, cdf_lengths, offsets)\n",
        "        y_string = encoder.flush()\n",
        "        y_strings.append(y_string)\n",
        "\n",
        "        return {\n",
        "            \"strings\": [y_strings, z_strings],\n",
        "            \"shape\": z.size()[-2:]\n",
        "        }\n",
        "\n",
        "    def decompress(self, strings, shape):\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        start_time = time.process_time()\n",
        "        \n",
        "        y_strings = strings[0][0]\n",
        "        z_strings = strings[1]\n",
        "\n",
        "        cdf = self.gaussian_conditional.quantized_cdf.tolist()\n",
        "        cdf_lengths = self.gaussian_conditional.cdf_length.reshape(-1).int().tolist()\n",
        "        offsets = self.gaussian_conditional.offset.reshape(-1).int().tolist()\n",
        "        decoder = RansDecoder()\n",
        "        decoder.set_stream(y_strings)\n",
        "\n",
        "        z_hat = self.entropy_bottleneck.decompress(z_strings, shape)\n",
        "        hyper_params = self.h_s(z_hat)\n",
        "        ctx_params_anchor = torch.zeros([z_hat.size(0), self.M * 2, z_hat.size(2) * 4, z_hat.size(3) * 4], device=z_hat.device)\n",
        "        gaussian_params_anchor = self.entropy_parameters(torch.cat([ctx_params_anchor, hyper_params], dim=1))\n",
        "        scales_anchor, means_anchor = gaussian_params_anchor.chunk(2, 1)\n",
        "        anchor_hat = self.decompress_anchor(scales_anchor, means_anchor, decoder, cdf, cdf_lengths, offsets)\n",
        "\n",
        "        ctx_params = self.context_prediction(anchor_hat)\n",
        "        gaussian_params = self.entropy_parameters(torch.cat([ctx_params, hyper_params], dim=1))\n",
        "        scales_nonanchor, means_nonanchor = gaussian_params.chunk(2, 1)\n",
        "        nonanchor_hat = self.decompress_nonanchor(scales_nonanchor, means_nonanchor, decoder, cdf, cdf_lengths, offsets)\n",
        "\n",
        "        y_hat = anchor_hat + nonanchor_hat\n",
        "        x_hat = self.g_s(y_hat)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        end_time = time.process_time()\n",
        "        cost_time = end_time - start_time\n",
        "\n",
        "        return {\n",
        "            \"x_hat\": x_hat,\n",
        "            \"cost_time\": cost_time\n",
        "        }\n",
        "\n",
        "    def ckbd_anchor_sequeeze(self, y):\n",
        "        B, C, H, W = y.shape\n",
        "        anchor = torch.zeros([B, C, H, W // 2]).to(y.device)\n",
        "        anchor[:, :, 0::2, :] = y[:, :, 0::2, 1::2]\n",
        "        anchor[:, :, 1::2, :] = y[:, :, 1::2, 0::2]\n",
        "        return anchor\n",
        "\n",
        "    def ckbd_nonanchor_sequeeze(self, y):\n",
        "        B, C, H, W = y.shape\n",
        "        nonanchor = torch.zeros([B, C, H, W // 2]).to(y.device)\n",
        "        nonanchor[:, :, 0::2, :] = y[:, :, 0::2, 0::2]\n",
        "        nonanchor[:, :, 1::2, :] = y[:, :, 1::2, 1::2]\n",
        "        return nonanchor\n",
        "\n",
        "    def ckbd_anchor_unsequeeze(self, anchor):\n",
        "        B, C, H, W = anchor.shape\n",
        "        y_anchor = torch.zeros([B, C, H, W * 2]).to(anchor.device)\n",
        "        y_anchor[:, :, 0::2, 1::2] = anchor[:, :, 0::2, :]\n",
        "        y_anchor[:, :, 1::2, 0::2] = anchor[:, :, 1::2, :]\n",
        "        return y_anchor\n",
        "\n",
        "    def ckbd_nonanchor_unsequeeze(self, nonanchor):\n",
        "        B, C, H, W = nonanchor.shape\n",
        "        y_nonanchor = torch.zeros([B, C, H, W * 2]).to(nonanchor.device)\n",
        "        y_nonanchor[:, :, 0::2, 0::2] = nonanchor[:, :, 0::2, :]\n",
        "        y_nonanchor[:, :, 1::2, 1::2] = nonanchor[:, :, 1::2, :]\n",
        "        return y_nonanchor\n",
        "\n",
        "    def compress_anchor(self, anchor, scales_anchor, means_anchor, symbols_list, indexes_list):\n",
        "        # squeeze anchor to avoid non-anchor symbols\n",
        "        anchor_squeeze = self.ckbd_anchor_sequeeze(anchor)\n",
        "        scales_anchor_squeeze = self.ckbd_anchor_sequeeze(scales_anchor)\n",
        "        means_anchor_squeeze = self.ckbd_anchor_sequeeze(means_anchor)\n",
        "        indexes = self.gaussian_conditional.build_indexes(scales_anchor_squeeze)\n",
        "        anchor_hat = self.gaussian_conditional.quantize(anchor_squeeze, \"symbols\", means_anchor_squeeze)\n",
        "        symbols_list.extend(anchor_hat.reshape(-1).tolist())\n",
        "        indexes_list.extend(indexes.reshape(-1).tolist())\n",
        "        anchor_hat = self.ckbd_anchor_unsequeeze(anchor_hat + means_anchor_squeeze)\n",
        "        return anchor_hat\n",
        "\n",
        "    def compress_nonanchor(self, nonanchor, scales_nonanchor, means_nonanchor, symbols_list, indexes_list):\n",
        "        nonanchor_squeeze = self.ckbd_nonanchor_sequeeze(nonanchor)\n",
        "        scales_nonanchor_squeeze = self.ckbd_nonanchor_sequeeze(scales_nonanchor)\n",
        "        means_nonanchor_squeeze = self.ckbd_nonanchor_sequeeze(means_nonanchor)\n",
        "        indexes = self.gaussian_conditional.build_indexes(scales_nonanchor_squeeze)\n",
        "        nonanchor_hat = self.gaussian_conditional.quantize(nonanchor_squeeze, \"symbols\", means_nonanchor_squeeze)\n",
        "        symbols_list.extend(nonanchor_hat.reshape(-1).tolist())\n",
        "        indexes_list.extend(indexes.reshape(-1).tolist())\n",
        "        nonanchor_hat = self.ckbd_nonanchor_unsequeeze(nonanchor_hat + means_nonanchor_squeeze)\n",
        "        return nonanchor_hat\n",
        "\n",
        "    def decompress_anchor(self, scales_anchor, means_anchor, decoder, cdf, cdf_lengths, offsets):\n",
        "        scales_anchor_squeeze = self.ckbd_anchor_sequeeze(scales_anchor)\n",
        "        means_anchor_squeeze = self.ckbd_anchor_sequeeze(means_anchor)\n",
        "        indexes = self.gaussian_conditional.build_indexes(scales_anchor_squeeze)\n",
        "        anchor_hat = decoder.decode_stream(indexes.reshape(-1).tolist(), cdf, cdf_lengths, offsets)\n",
        "        anchor_hat = torch.Tensor(anchor_hat).reshape(scales_anchor_squeeze.shape).to(scales_anchor.device) + means_anchor_squeeze\n",
        "        anchor_hat = self.ckbd_anchor_unsequeeze(anchor_hat)\n",
        "        return anchor_hat\n",
        "\n",
        "    def decompress_nonanchor(self, scales_nonanchor, means_nonanchor, decoder, cdf, cdf_lengths, offsets):\n",
        "        scales_nonanchor_squeeze = self.ckbd_nonanchor_sequeeze(scales_nonanchor)\n",
        "        means_nonanchor_squeeze = self.ckbd_nonanchor_sequeeze(means_nonanchor)\n",
        "        indexes = self.gaussian_conditional.build_indexes(scales_nonanchor_squeeze)\n",
        "        nonanchor_hat = decoder.decode_stream(indexes.reshape(-1).tolist(), cdf, cdf_lengths, offsets)\n",
        "        nonanchor_hat = torch.Tensor(nonanchor_hat).reshape(scales_nonanchor_squeeze.shape).to(scales_nonanchor.device) + means_nonanchor_squeeze\n",
        "        nonanchor_hat = self.ckbd_nonanchor_unsequeeze(nonanchor_hat)\n",
        "        return nonanchor_hat\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        update_registered_buffers(\n",
        "            self.gaussian_conditional,\n",
        "            \"gaussian_conditional\",\n",
        "            [\"_quantized_cdf\", \"_offset\", \"_cdf_length\", \"scale_table\"],\n",
        "            state_dict,\n",
        "        )\n",
        "        super().load_state_dict(state_dict)\n",
        "\n",
        "    def update(self, scale_table=None, force=False):\n",
        "        if scale_table is None:\n",
        "            scale_table = get_scale_table()\n",
        "        updated = self.gaussian_conditional.update_scale_table(scale_table, force=force)\n",
        "        updated |= super().update(force=force)\n",
        "        return updated"
      ],
      "metadata": {
        "id": "ATuLk7OhqgKX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1VCEcfAduEW1"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}